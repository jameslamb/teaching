---
title: R Programming (Code Supplement)
output:
  html_document:
    toc: true
    theme: spacelab
---

```{r setOpts, echo = FALSE}
knitr::opts_chunk$set(
    eval = TRUE
    , echo = TRUE
    , warning = FALSE
    , message = FALSE
)
```

<h1>Week 3 Programming Supplement</h1>

<h2>Logical Operators</h2>

Often in your code, you'll want to do/not do something or select / not select some data based on a logical condition (a statement that evaluates to TRUE or FALSE). Here are some examples of how to construct these statements in R.

```{r logicalCond1}
# "and" logic is expressed with "&"
TRUE & TRUE   # TRUE
TRUE & FALSE  # FALSE
FALSE & FALSE # FALSE
-5 < 5 & 3 > 2 # TRUE

# "or" logic is expressed with "|"
TRUE | TRUE    # TRUE
TRUE | FALSE   # TRUE
FALSE | FALSE  # FALSE
3 < 8 | 8 > 19 # TRUE
```

The most common operators used to generate logicals are `>`, `<`, `==`, and `!=`

```{r logicalCond2}
# "equality" logic is specified with "=="
3 == 3   # TRUE
4 == 4.1 # FALSE

# "not" logic is specified with !. In a special case, != signifies "not equal"
!TRUE            # FALSE
!FALSE           # TRUE
! (TRUE | FALSE) # FALSE
4 != 5           # TRUE

# "greater than" and "less than" logic are specified in the way you might expect
5 < 5  # FALSE
6 <= 6 # TRUE
4 > 2  # TRUE
3 >= 3 # TRUE
```

As we learned in week two, you can use vectors of logicals (TRUE and FALSE) to subset other objects. As a general rule, when you put a vector on the left-hand side of a logical condition like `==` or `>`, you will get back a vector as a result.

```{r logicalCond3}
# Load some data
data("mtcars")

# Create a logical index. Note that we get a VECTOR of logicals back
bigCarIndex <- mtcars$wt > 4

# Taking the SUM of a logical vector tells you the number of TRUEs.
# Taking the MEAN of a logical vector tells you the proportion of TRUEs
sum(bigCarIndex)
mean(bigCarIndex)

# You can use this for subsetting
mtcars[bigCarIndex,]
```

<h2>Factors</h2>

Imagine that you want to build a model of the relationship between resource wealth and quality-of-life outcomes like life expectancy. You got out to the World Bank to grab some data, and the dataset you get includes a column called "region" with values like "Africa", "European Union", and "South America". How can you use this variable in a model or for generating region-by-region summary stats? This is where R's **factor type** comes in.

```{r factorVar1}
# Sample Data
wbDF <- data.frame(
    country = c("Egypt", "Cyprus", "Nicaragua", "Colombia", "Germany")
    , region  = c("Africa", "European Union", "South America", "South America", "European Union")
    , lifeexp = c(74.5, 78.0, 75.6, 72.3, 81.9)
)

# Check classes...see that "region" is a "Factor" by default!
str(wbDF)
```

What does it mean for `region` to be a factor? Essentially, a factor is a categorical variable. R uses a cool trick to save memory when storing factors...internally, R will convert factor values to integers and then keep aroudn a single table the tells it, e.g., that 1 = "Africa", 2 = "European Union", etc..

```{r factorVar2}
# Check it out! R has assigned integer values to the "region" variable
as.integer(wbDF$region)

# But you can also access the character values if you want
as.character(wbDF$region)

# For more, see:
str(wbDF$region)
levels(wbDF$regions)
```

<h2>File Paths</h2>

Whenever you find yourself reading data into R or writing data out of it, you will need to work with file paths. File paths are just addresses on your computer's file system. These paths can either be *relative* (expressed as steps above/below your current location) or *absolute* (full addresses). 

All relative paths in R are relative to your **working directory**, a single location that you can set and reset any time in your session.

```{r setwdExample, eval = FALSE, echo = TRUE}
# Check and then change the current working directory
print(getwd())
sandbox_repo <- file.path(Sys.getenv("HOME"), "repos", "sandbox")
setwd(sandbox_repo)

# Reference a file with a full path
myDF <- read.csv(
  file = file.path(sandbox_repo, "data", "some_data.csv")
)

# Reference a file with a relative path
myDF <- read.csv(file = "./data/some_data.csv")
```

R provides a few other utilities for working with file paths and directory structures.

* `file.path()`: create a filepath from multiple parts
* `file.exists()`: returns `TRUE` is a file exists and  `FALSE` if it doesn't
* `list.files()`: get a character vector with names of all files found in a directory
* `dir.exists()`: returns `TRUE` is a directory exists and  `FALSE` if it doesn't
* `dir.create()`: create a new directory

```{r moarFilez, eval = FALSE, echo = TRUE}
# List all the files in some directory and put the list in a vector
docs_dir <- file.path(Sys.getenv("HOME"), "some_folder", "docs")
theFiles <- list.files(path = docs_dir)

# Create a directory if it doesn't exist
slide_dir <- file.path(docs_dir, "slides")
if (!dir.exists(slide_dir)) {
    dir.create(slide_dir)
}

# Check if a file exists
report_file <- file.path(docs_dir, "report.xlsx")
myFileExists <- file.exists(report_file)
```

<h2>Downloading files from the internet</h2>

To download files hosted on the internet, you can use `download.file()`.

```{r, eval = FALSE, echo = TRUE}
download.file(
  url = "https://raw.githubusercontent.com/jameslamb/teaching/main/mu_rprog/sample-data/iris.csv"
  , destfile = "iris.csv"
)
```

<h2>CSV</h2>

CSV stands for "comma-separated values". This format is a really common to share small, tabular datasets because it is just a text file, and can be ready by many different types of programs. R has several options for reading this type of file.

* `read.csv()`: base R function for reading CSVs into a `data.frame`
* `data.table::fread()`: super-fast CSV reader that creates a special type of `data.frame` called a `data.table`
* `read.delim()`: similar to `read.csv()`, but can read files with any delimiter
* `readr::read_csv()`: CSV reader from RStudio

A CSV is just a plaintext file where the first row is column names separated by columns and each following row is an observation with columns separated by commas.

```text
date,open,close
01-01-2012,10.5,8.9
01-02-2012,8.9,10.3
```

To begin this example, download the example file from the course repository.

```{r, eval=FALSE, echo=TRUE}
iris_url <- "https://raw.githubusercontent.com/jameslamb/teaching/main/mu_rprog/sample-data/iris.csv"
iris_file <- "iris.csv"
download.file(
  url = iris_url
  , destfile = iris_file
)
```

Then read it in with `read.csv()` and inspect it with `head()`.

```{r, eval=FALSE, echo=TRUE}
irisDF <- read.csv(
  file = iris_file
  , header = TRUE
)
print(head(irisDF))
```

This function can also read CSV data directly from files on the internet.

```{r, eval=FALSE, echo=TRUE}
irisDF <- read.csv(
  file = iris_url
  , header = TRUE
)
print(head(irisDF))
```

<h2>Excel</h2>

In the Economics / Business world (and many other areas!), Microsoft Excel is pretty much unavoidable. You'll get data from the internet, your colleagues, clients, etc. in Excel format and may want to work with it in R. There are a few packages for doing this, but in this course we'll focus on [openxlsx](https://cran.r-project.org/web/packages/openxlsx/openxlsx.pdf).

NOTE: This package requires certain Java components that you may not have on your machine. If you run into issues, I recommend 1) installing an updated version of [JRE](http://www.oracle.com/technetwork/java/javase/downloads/jre8-downloads-2133155.html) or 2) exploring other packages like [xlsx](https://cran.r-project.org/web/packages/xlsx/xlsx.pdf) or [readxl](https://cran.r-project.org/web/packages/readxl/readxl.pdf).

To begin this example, download the example file from the course repository.

```{r, eval=FALSE, echo=TRUE}
gdp_url <- "https://raw.githubusercontent.com/jameslamb/teaching/main/mu_rprog/sample-data/gdp.xlsx"
gdp_file <- "gdp.xlsx"
download.file(
  url = gdp_url
  , destfile = gdp_file
)
```

Then read it in with `openxlsx::read.xlsx()` and view it with `head()`.

```{r readingExcel, eval = FALSE, echo = TRUE}
library(openxlsx)
gdpDF <- openxlsx::read.xlsx(
    xlsxFile = gdp_file
)
print(head(gdpDF))
```

This function can also read Excel data directly from files on the internet.

```{r, eval=FALSE, echo=TRUE}
library(openxlsx)
gdpDF <- openxlsx::read.xlsx(
    xlsxFile = gdp_url
)
print(head(gdpDF))
```

You can also use this package to write Excel files. You can do really complicated stuff (like conditional formatting, named ranges, and live formulas) from inside of R. It's tough to set up at first, but can be VERY useful if you find yourself spending a lot of time running routine reports whose format is the same from update to update.

```{r writingExcel, eval = FALSE, echo = TRUE}
# load mtcars
data("mtcars")

# create a workbook object in R
testWB <- openxlsx::createWorkbook()

# Add sheets and data
openxlsx::addWorksheet(
    wb = testWB
    , sheetName = "car_data"
)
openxlsx::writeData(
    wb = testWB
    , sheet = "car_data"
    , x = mtcars
)

# Write out the file
testing_file <- file.path(Sys.getenv("HOME"), "testing.xlsx")
openxlsx::saveWorkbook(
    wb = testWB
    , file = testing_file
)
```

<h2>JSON</h2>

JSON ("Javascript Object Notation") is a standard format for "semi-structured" or "nested" data. It's a plain-text format that can be used by many programs and programming languages.

```
{
  "status": 200,
  "data": [
    {"customer_name": "Lupe", "purchases": 10},
    {"customer_name": "Wale", "purchases": 30}
  ]
}
```

To begin this example, download the example file from the course repository.

```{r, eval=FALSE, echo=TRUE}
tweet_url <- "https://raw.githubusercontent.com/jameslamb/teaching/main/mu_rprog/sample-data/tweets.json"
tweet_file <- "tweets.json"
download.file(
  url = tweet_url
  , destfile = tweet_file
)
```

Open the file in a text editor and inspect its contents. It contains a sample response from the Twitter API, which is used by developers to build applications that interact with Twitter. Here's a preview:

```
{
  "created_at": "Mon May 06 20:01:29 +0000 2019",
  "id": 1125490788736032800,
  "id_str": "1125490788736032770",
  "text": "Today's new update means that you can finally add Pizza Cat to your Retweet with comments! Learn more about this ne… https://t.co/Rbc9TF2s5X",
  "display_text_range": [
    0,
    140
  ],
  "truncated": true,
  "in_reply_to_status_id": null,
  "in_reply_to_status_id_str": null,
  "in_reply_to_user_id": null,
  "in_reply_to_user_id_str": null,
  "in_reply_to_screen_name": null,
  "user": {
    "id": 2244994945,
    "id_str": "2244994945",
    "name": "Twitter Dev",
    "screen_name": "TwitterDev",
    "location": "Internet",
    "url": "https://developer.twitter.com/",
    "description": "Your official source for Twitter Platform news, updates & events. Need technical help? Visit https://twittercommunity.com/ ⌨️ #TapIntoTwitter",
    "translator_type": "null",
```

There are a few packages for reading this type of data in R. The example below uses one of the most popular, `jsonlite`. Read in the file with `jsonlite::fromJSON()` and view its contents with `str()`.

```{r, eval=FALSE, echo=TRUE}
tweetList <- jsonlite::fromJSON(
  txt  = tweet_file
  , simplifyDataFrame = FALSE
)

str(tweetList, max.level = 3)
```

This function can also read JSON data directly from files on the internet.

```{r, eval=FALSE, echo=TRUE}
tweetList <- jsonlite::fromJSON(
  txt  = tweet_url
  , simplifyDataFrame = FALSE
)
str(tweetList, max.level = 3)
```

<h2>Specialness of NAs</h2>

`NA` is a special object in R, used to capture the idea of "a value whose value is unknown". Confusing, right? We're going to go through a few examples to get you feeling comfortable with missing values. They're an inevitability in real-world data.

**PRO TIP**: See `?NA` for R's documentation on the nuances of `NA`

```{r introToNAs}
# Create a vector w/ missing data
some_nums <- c(1,2,NA, 6, NA, 8)
print(some_nums)

# Use is.na() to get a vector of TRUE/FALSE for the question "is this element NA?"
is.na(some_nums)

# Confirm that even w/ NAs, R still knows this is a numeric vector
class(some_nums)
```

<h2>Strategy 1: Total Eradication</h2>

The first approach you may take to dealing with `NA` values is to simply drop them from your data. If you don't think these missing data have any business value and your dataset is big enough that you can afford to drop some rows / columns, this is the right move for you.

```{r removeNAs}
# Removing NAs for vectors
top5 <- c(
  "Wale"
  , "Chance"
  , NA
  , "Lupe Fiasco"
  , "Shad"
  , "Kanye"
  , NA
)
print(top5)
top5cleaned <- top5[!is.na(top5)]
print(top5cleaned)

# Removing rows with ANY NAs for data.frames
myDF <- data.frame(
    x = c(1, 2, NA, 4)
    , y = c(NA, TRUE, FALSE, TRUE)
    , z = c("hey", "there", NA, "friends")
)
cleanDF <- myDF[complete.cases(myDF), ]
```

<h2>Strategy 2: Handle on Subsets</h2>

You may find the "remove all the NAs everywhere" strategy a bit too aggreesive for your use case. If you have a 100-variable dataset and a single variable (column) is 90\% NA values, do you really want to drop every row where that variable is NA? A better approach might be to selectively subset out columns where missing values are most severe before using `complete.cases()` to remove rows.

```{r subsetNAwisely}
# Create a data frame where some variable have more NAs than others
testDF <- data.frame(
    var1 = sample(c(rnorm(99), NA), 200, replace = TRUE)
    , var2 = sample(c(rnorm(50), rep(NA, 50)), 200, replace = TRUE)
    , var3 = sample(c(rnorm(5), rep(NA, 95)), 200, replace = TRUE)
)

# Find columns that are more than 90% missing values
.percent_na <- function(a_vector){
    return(sum(is.na(a_vector)/length(a_vector)))
}
colsToDrop <- apply(testDF, MARGIN = 2, .percent_na) > 0.9
cleanDF <- testDF[, !colsToDrop]

# Remove rows w/ remaining NAs
cleanDF <- cleanDF[complete.cases(cleanDF),]
```

<h2>Strategy 3: Imputation</h2>

A final strategy, particularly useful in modeling contexts, is to use some [imputation strategy](https://www.analyticsvidhya.com/blog/2016/03/tutorial-powerful-packages-imputing-missing-values/) to replace `NA` values with reasonable alternatives. One common approach (and my favorite), the `roughfix` method. It works like this:
- For numeric columns, replace NAs with the column median
- For categorical columns, replace NAs with the most common value

```{r imputation}
# Create a data frame where some variable have more NAs than others
testDF <- data.frame(
  var1 = sample(c(rnorm(99), NA), 500, replace = TRUE)
  , var2 = sample(c(rnorm(70), rep(NA, 30)), 500, replace = TRUE)
  , var3 = sample(c(rnorm(85), rep(NA, 15)), 500, replace = TRUE)
)

# Clean up w/ roughfix
library(randomForest)
cleanDF <- randomForest::na.roughfix(testDF)
```

<h2>Intro to the Base Plotting System</h2>

R is famous, in part, for its ability to create production-quality plots within the default graphics package it ships with. This plotting paradigm is often referred to as "the base plotting system", and we're going to walk through a few examples of it this week.

The essential idea of the base plotting system is to build up plots in layers. You first create a simple 1-variable line plot, for example, then "add on" a legend, more variables, other plot types, etc. We'll try a few examples using the sample data created below.

```{r getPlotData}
# Load up the famous iris dataset
data("iris")
head(iris, n = 10)
```

Let's start with a simple line plot to answer the question *are sepal length and sepal width related?*.

```{r baseLinePlot}
# Create a simple line plot
plot(
  x = iris$Sepal.Length
  , y = iris$Sepal.Width
  , type = "p"
)

# Try again, but with labels!
plot(
  x = iris$Sepal.Length
  , y = iris$Sepal.Width
  , main = "My Second R plot!"
  , xlab = "sepal length"
  , ylab = "sepal width"
  , type = "p"
)

# Try it AGAIN, this time coloring by species and a legend
plot(
  x = iris$Sepal.Length
  , y = iris$Sepal.Width
  , main = "My Third R plot!"
  , xlab = "sepal length"
  , ylab = "sepal width"
  , type = "p"
  , col = iris$Species
  , bg = iris$Species
  , pch = 21
)

# Add a legend
legend(
  x = 7
  , y = 4.3
  , unique(iris$Species)
  , col = 1:length(iris$Species)
  , pch = 1
)
```

The base plotting system can be a great tool for quick exploratory analysis of data, such as examination of the distribution of variables in your data.

```{r histAndDensity}
# Minimal Histogram
hist(iris$Petal.Length)

# Better histogram
hist(
  iris$Petal.Length
  , main = "Distribution of petal length"
  , xlab = "petal length"
  , breaks = 25
)

# Empirical density
plot(
  density(iris$Petal.Length)
  , main = "Empirical density of petal length"
  , col = "blue"
)
```

You can add more than one variable to these plots! Let's compare the densities of Sepal length by species

```{r compareDensities}

# Overlay densities of Petal length by species
plot(
  density(iris[iris$Species == "setosa", "Petal.Length"])
  , main = "Empirical density of petal length"
  , col = "blue"
  , xlim = c(0, 7)
  , ylim = c(0, 2.5)
)
lines(density(iris[iris$Species == "versicolor", "Petal.Length"]), col = "red")
lines(density(iris[iris$Species == "virginica", "Petal.Length"]), col = "black")

# Add a legend
legend(
  x = 5.5
  , y = 2.25
  , legend = unique(iris$Species)
  , col = c("blue", "red", "black")
  , pch = 1
)
```

You can control the plotting options to make a grid of plots. The code below creates a 2x2 grid with a density for Sepal Width and scatter plots of the other three variables against sepal width.

```{r gridOfPlots}
# Set global options
par(mfrow = c(2,2))

# Dump in some plots
plot(
  density(iris$Sepal.Width)
  , main = "Empirical density of petal length"
  , col = "red"
)
plot(
  x = iris$Sepal.Width
  , y = iris$Sepal.Length
  , col = iris$Species
  , bg = iris$Species
  , pch = 21
)
plot(
  x = iris$Sepal.Width
  , y = iris$Petal.Length
  , col = iris$Species
  , bg = iris$Species
  , pch = 21
)
plot(
  x = iris$Sepal.Width
  , y = iris$Petal.Width
  , col = iris$Species
  , bg = iris$Species
  , pch = 21
)

# reset options
par(mfrow = c(1,1))
```

<h2>A Note On Graphics Devices</h2>

When R (or any other program!) creates plots, it needs to know where to put them! When you call `plot()` or other commands from within and RStudio session, the default is to just display the resulting figure in the "Plots" pane. However, you can use other **graphics devices** (places to put visual output) to tell R to put your figures elsewhere.

```{r path2png, eval = FALSE, echo = TRUE}
# Create 10 plots in a loop
outDir <- getwd()
for (i in 1:10){
    # Open a connection to a .png file
    filePath <- paste0(outDir, "/plot_", i, ".png")
    png(filePath)
    
    # Write out a plot to that file
    plot(x = rnorm(100), y = rnorm(100))
    
    # Close the connection to that file
    dev.off()
}
```
