---
title       : ECON 6114 - R Programming
subtitle    : Week 4
author      : James Lamb
job         : Engineer | Saturn Cloud
framework   : io2012
highlighter : highlight.js
hitheme     : tomorrow
widgets     : [bootstrap]
mode        : selfcontained
lib_cdn     : "https://cdn.rawgit.com/ramnathv/slidifyLibraries/master/inst/libraries"
knit        : slidify::knit2slides
---

<!--Read in JavaScript function that prints footer bubbles-->
<script src="assets/js/footer_bubbles.js"></script>

<!--Define background image for title slide-->
<style>
.title-slide {
  background-image:url("assets/img/Week4_gonzo.png");
  background-size: cover;
}
</style>

<footer>
  <hr></hr>
  <span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>R + Statistics = Besties 5 evah</h2>

<center><img src="assets/img/Week4_nice_guys.gif" height=350px width = 650px></center>

--- .toc_slide &twocol

<footer>
  <hr></hr>
  <span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Contents</h2>

*** =left

<b class="toc_header"> I. Statistical Analysis in R </b>
<ol class = "toc" type="none">
    <li> R Was Made for Statistics!<span style="float:right">                  5 </span></li>
    <li> Exploring the Data <span style="float:right">                       6-8 </span></li>
    <li> Simple OLS Model <span style="float:right">                           9 </span></li>
    <li> Functionalizing Your Pipeline <span style="float:right">             10 </span></li>
    <li> OLS With Multiple RHS Variables <span style="float:right">            11 </span></li>
    <li> Tree-Based Methods <span style="float:right">                     12-13 </span></li>
    <li> Model Evaluation                      <span style="float:right">    14 </span></li>
</ol>

<b class="toc_header"> II. Combining and Transforming Data Frames</b>
<ol class = "toc" type="none">
    <li> Columnwise Combination<span style="float:right"> 16-17 </span></li>
    <li> Rowwise Combination<span style="float:right">    18-19 </span></li>
</ol>

*** =right

<b class="toc_header"> III. How to Write Statistical Software</b>
<ol class = "toc" type="none">
    <li> Getting Your Project Off the Ground<span style="float:right"> 21 </span></li>
    <li> Step 1: Build a Comment Skeleton<span style="float:right">    22 </span></li>
    <li> Step 2: Define Functions <span style="float:right">           23 </span></li>
    <li> Step 3: Fill in Your Code! <span style="float:right">         24 </span></li>
</ol>

<b class="toc_header"> IV. Working with Strings </b>
<ol class = "toc" type="none">
    <li> Common Preprocessing Steps <span style="float:right"> 26 </span></li>
    <li> Intro to Regular Expressions <span style="float:right"> 27-28 </span></li>
    <li> Tokenization <span style="float:right"> 29 </span></li>
    <li> Counting Words in Text <span style="float:right"> 30 </span></li>
</ol>

<b class="toc_header"> V. Final Project Discussion </b>
<ol class = "toc" type="none">
    <li> Code Review Tips <span style="float:right">       32 </span></li>
    <li> Scripting: Style Notes <span style="float:right"> 33 </span></li>
    <li> Lingering Questions <span style="float:right">    34 </span></li>
</ol>

--- .section_slide

<h2>Section I.</h2>
<hr></hr>
</br></br></br>
<h2>Statistical Analysis in R</h2>

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(1,10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>R Was Made for Statistics!</h2>

In this section, we're going to walk through all the steps of basic statistical analysis: getting data, exploring it, creating feature, building models, evaluating models, and comparing those models' performance.

<center><img src="../slides/assets/img/statistics.jpg"></center>

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(2,10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Getting and Splitting the Data</h2>

We're going to work with R's [swiss](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/swiss.html) dataset. This cross-sectional dataset contains measures of fertility and some economic indicators collected in Switzerland in 1888. Our first task will be to load the data and immediately hold out a piece of it as [testing data](http://info.salford-systems.com/blog/bid/337783/Why-Data-Scientists-Split-Data-into-Train-and-Test). The idea here is that when we evaluate the performance of our models later on, it will be better to do it on data that the models haven't seen. This will give a more honest picture of how well they might perform on new data.

In this exercise, we're going to evaluate the following question: **Can we predict fertility based on regional socioeconomic characteristics?**

<br>
Please follow along with the code in the [Week 4 Programming Supplement](https://jameslamb.github.io/teaching/mu_rprog/code/Week4_Supplement.html).

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(3,10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Examine Your Training Data</h2>

Once you've split your data into training and test, you should start poking it a bit to see if you find anything interesting. You can use `str()` to view the contents of your data objects, `summary()` to view some basic summary statistics on data frame columns, and `cor()` to get a correlation matrix between all pairs of numeric variables.

```{r eda}
# Look at the structure
str(swiss)
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(4,10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Hypothesis Testing</h2>

Though orthodox hypothesis tests have been [maligned in the scientific press recently](http://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/), they are still enormously valuable tools for discovering differences in datasets and evaluates relationships between variables.

One approach to looking for statistically interesting features (right-hand-side variables) involves binning those variables into "above median" and "below median", and using a paired t-test to see whether or not the variable is statistically related to the target.

```{r hypothesisTests, eval = FALSE}
# 1. Is fertility very different in provinces with above-median % of men in Agriculture
swiss$majority_agg <- swiss$Agriculture > median(swiss$Agriculture)
t.test(
  Fertility ~ majority_agg
  , data = swiss
)
```

<br>
For more, see the [Week 4 Programming Supplement](https://jameslamb.github.io/teaching/mu_rprog/code/Week4_Supplement.html).

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(5,10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Simple OLS Model</h2>

OK now that we've done some basic preprocessing and exploration, it's time to start fitting models! Let's begin with a simple one-variable OLS regression, estimated using the `lm()` command.

```{r simpleOLS, eval = FALSE}
# Simple regression: Fertility = f(Agriculture)
mod1 <- lm(
  Fertility ~ Agriculture
  , data = swiss
)
```

Once you have the fitted model, you can pass it and some new data to `predict()` to generate predictions. Model evaluation metrics commonly used in regression problems:
- [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error)
- [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error)
- [mean absolute percent error](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error)

**shameless plug:** If you want to go deep into the world of error metrics, you can check out the [documentation in this EViews Add-in](https://github.com/jameslamb/ML4EVIEWS/blob/master/tscval/Docs/tscval.pdf) my friend Rita and I wrote.

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(6, 10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Wrap Parts of Your Pipeline in Functions</h2>

The error metric calculations and plotting we just did seem general enough to apply to other models of this phenomenon. Since we could reuse the code for other models, we should just wrap it in a function so it's easy to call downstream.

Wrapping your analytics pipeline in a function has a few other benefits:
- Easy to test many different configurations
- Easy to change the code if needed
- Code is expressive, understandable

<br>
For more, see the [Week 4 Programming Supplement](https://jameslamb.github.io/teaching/mu_rprog/code/Week4_Supplement.html).

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(7,10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>OLS With Multiple RHS Variables</h2>

To add more variables to a model in R, you have to use formula notation. I've specified specific right-hand side variables in this case, but if you want to express the idea "all of the X variables", you can use a statement like `Fertility ~ .`.

```{r olsMoreVars, eval = FALSE}
# Fit
mod2 <- lm(
  Fertility ~ Education + Infant.Mortality + Examination_above_median
  , data = swiss
)

# Predict + Evaluate
regPreds2 <- EvaluateModel(
  mod2
  , testDF = swissTestDF
  , modelName = "Expanded OLS"
)
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(8,10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Regression Trees</h2>

Linear regressions are powerful tools, but there are certain classes of complex relationships that they are unable to express and therefore unable to "learn" when trained on data.

Regression Trees are one mainstream tool used to fit complex functions. They recursively partition the dataset, trying to find "local" models of subsets of the data which, together, provide a better fit than the single "global" OLS model we're used to fitting.

The details of tree-based learning are outside the scope of this class, but I encourage you to check out [A Visual Introduction to Machine Learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/) to at least get the general intuition behind this and other ML techniques.

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(9,10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Random Forests</h2>

For larger datasets than the one we're working with in this exercise, you may find that a single decision tree is not expressive enough or that one strong signal overpowers all the other variables. To correct for this, many analysts will use a "forest" of decision trees. The implementation details are again outside the scope of this course: see [Leo Breiman's excellent site](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm) if you're curious in learning more about this algorithm.

I only mention the random forest here to demonstrate how easy it is to fit and predict with complex statistical models in R.

```{r randomForest, eval = FALSE}
# Fit
rfMod <- randomForest::randomForest(
  Fertility ~ .
  , data = swiss
  , ntree = 50
  , do.trace = TRUE
)

# Evaluate
rfPreds <- EvaluateModel(
  rfMod
  , swissTestDF
  , "Random Forest (ntree=100)"
)
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(10,10)</script>I. Statistical Analysis in R<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Accuracy Comparison</h2>

In a real project, at some point you will find yourself saying "OK, I have all these models. What should I actually use to generate predictions?". This question was our motivation for holding out a test set at the beginning of this walkthrough. Accuracy when predicting on previously unseen data is a totally defensible measure for choosing the "best" model from a set of candidate models.

Let's see how the models we trained in this exercise performed:

```{r modelEval, eval = FALSE}
# Build a table showing performance of each model type on the holdout
compDF <- data.frame(
  modelName = c("Expanded OLS", "Decision Tree", "Random Forest (ntree=100)")
  , MAE     = c(regPreds2$MAE, dtPreds$MAE, rfPreds$MAE)
  , MSE     = c(regPreds2$MSE, dtPreds$MSE, rfPreds$MSE)
  , MAPE    = c(regPreds2$MAPE, dtPreds$MAPE, rfPreds$MAPE)
)
print(compDF)
```

--- .section_slide

<h2>Section II.</h2>
<hr></hr>
</br></br></br>
<h2>Combining and Transforming Data Frames</h2>

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(1,4)</script>II. Combining and Transforming Data Frames<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Columnwise Combination With cbind</h2>

In situations where you have multiple data frames with the same rows but different columns, you can combine them column-wise with R's `cbind` command. Note that this command will only work if the two data frames to be joined have the same number of rows AND those rows refer to the same observation.

**cbind = "column-wise bind"**

```{r cbindExample}
dealerDF1 <- data.frame(
  dealer_id = c(1:20)
  , avg_price = runif(20, min = 15, max = 75)
  , avg_margin = runif(20, min = -0.1, max = 0.45)
)

dealerDF2 <- data.frame(
    dealer_id = c(1:20)
    , industry = sample(
        c("Mining", "Healthcare", "Robot Stuff")
        , size = 20
        , replace = TRUE
    )
)
fullDF <- cbind(dealerDF1, dealerDF2)
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(2,4)</script>II. Combining and Transforming Data Frames<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Column Matching with merge</h2>

`cbind` works in the limited situation where you have two data frames that can just be jammed together (same number of rows + rows line up). This doesn't happen too often. However, it is VERY common in data science workflows to have two mismatched tables of data from different sources and to want to combine them by matching on one or more keys. Think `JOIN` in SQL or `VLOOKUP` in Excel. To perform this operation in R, you can use the `merge` command.

```{r mergeExample}
dealerDF1 <- data.frame(
    dealer_id = c(20:1)
    , avg_price = runif(20, min = 15, max = 75)
    , avg_margin = runif(20, min = -0.1, max = 0.45)
)

dealerDF2 <- data.frame(
    dealer_id = c(1:20)
    , industry = sample(
        c("Mining", "Healthcare", "Robot Stuff")
        , size = 20
        , replace = TRUE
    )
)

fullDF2 <- merge(
    dealerDF1
    , dealerDF2
    , by = "dealer_id"
)
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(3,4)</script>II. Combining and Transforming Data Frames<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Rowwise Combination With rbind</h2>

So far we've talked about merging columns from different tables. But what if you want to merge rows? For example, imagine that you are a researcher in a lab studying some natural phenomenon. You may take multiple samples (measuring the same variables) and then want to put them together into a single data frame to build a model. For this case, we can use R's `rbind` function.

**rbind = "row-wise bind"**

```{r rbindExample}
sample1 <- data.frame(
    startTime = seq.Date(
        from = as.Date("2016-01-01")
        , to = as.Date("2016-06-30")
        , length.out = 180
    )
    , value = rnorm(180, 5, 2.5)
    , sampleId = rep("sample1", 180)
)

sample2 <- data.frame(
    startTime = seq.Date(
        from = as.Date("2016-07-01")
        , to = as.Date("2017-03-31")
        , length.out = 210
    )
    , value = rnorm(210, 5, 2.5)
    , sampleId = rep("sample2", 210)
)

fullDF <- rbind(sample1, sample2)
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(4,4)</script>II. Combining and Transforming Data Frames<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Rowwise Combination of Many Tables with rbindlist</h2>

`rbind` works as a strategy for combining two tables, but what if you have 5 tables? 10? 1000? For those situations, you should checkout `rbindlist` from the `data.table` package.

```{r rbindlistExample, eval = FALSE}
sample1 <- data.frame(
    startTime = seq.Date(
        from = as.Date("2016-01-01")
        , to = as.Date("2016-06-30")
        , length.out = 180
    )
    , value = rnorm(180, 5, 2.5)
)

sample2 <- data.frame(
    startTime = seq.Date(
        from = as.Date("2016-07-01")
        , to = as.Date("2017-03-31")
        , length.out = 210
    )
    , value = rnorm(210, 5, 2.5)
)

sample3 <- data.frame(
    startTime = seq.Date(
        from = as.Date("2017-05-01")
        , to = as.Date("2017-12-31")
        , length.out = 240
    )
    , value = rnorm(240, 5, 2.5)
)

fullDF <- data.table::rbindlist(
    list(sample1, sample2, sample3)
)
```

--- .section_slide

<h2>Section III.</h2>
<hr></hr>
</br></br></br>
<h2>How to Write Statistical Software</h2>

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(1,4)</script>III. How to Write Statistical Software<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Getting Your Project Off the Ground</h2>

OK so you have a business question, you've chosen your toolchain (presumably with R), and you have some data in hand. You sit down to write code and, well...

<center><img src="assets/img/spongebob.gif"></center>

<br>
In this section, we'll to walk through the process of building a non-trivial script from scratch.

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(2,4)</script>III. How to Write Statistical Software<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Step 1: Build a Comment Skeleton</h2>

Resist the urge to just start writing code. Investing a few minutes upfront in thinking through the structure of your code will pay off in a big way as the project evolves and grows more complicated. Trust me.

First, just write down the main things you want to do. In this exercise, we're going to write some R code that can generate n-page "books" or random sentences in English.

```{r fromScratch}
#=== Write an R script that writes a book! ===#

# Function to create random sentences

# Function to create a "page" with n sentences

# Function to create a "book" with m pages

# Call the book function and create a 5-page book
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(3,4)</script>III. How to Write Statistical Software<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Step 2: Define Functions</h2>

Next, fill in the high-level outline with slightly more specifics. Try to strategize about the functions you'll need to implement and the individual steps that will have to happen inside each of those functions. This will probably change once you start writing code, but in my experience it's always easier to have a plan and change it.

<center><img src="assets/img/functions.jpg"></center>

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(4,4)</script>III. How to Write Statistical Software<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Step 3: Fill in Your Code!</h2>

You'll spend the most time on this and you will have to go through it many times before you're feeling comfortable with the code. I've given one implementation below. The point here is not to show you how to create a book-writing app, but rather to demonstrate that this somewhat complicated task was made easier by breaking it into smaller, more manageable pieces.

<br>
For more, see the [Week 4 Programming Supplement](https://jameslamb.github.io/teaching/mu_rprog/code/Week4_Supplement.html).

--- .section_slide

<h2>Section IV.</h2>
<hr></hr>
</br></br></br>
<h2>Working With Strings</h2>

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(1,5)</script>IV. Working with Strings<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Common Preprocessing Steps</h2>

In this section, we're going to revisit the [Shakespeare corpus](https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt) we looked at in Week 2 and implement a basic "keyword extraction" pipeline. Let's start by loading it and doing some common string preprocessing on it.

```{r startTextAnalysis, echo = TRUE, eval = FALSE}
# Grab a random 5000 lines from the corpus (skipping a bunch of that MIT text at the beginning)
shakespeareFile <- "https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt"
bsText <- readLines(con = shakespeareFile, n = 10000)[5001:10000]

# 1 - Convert everything to lowercase
bsText <- tolower(bsText)

# 2 - Trim leading and trailing whitespace (e.g. change "   a" to "a")
bsText <- trimws(bsText)

# 3 - Remove empty lines
bsText <- bsText[sapply(bsText, nchar)>0]
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(2,5)</script>IV. Working with Strings<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Intro to Regular Expressions</h2>

After applying these basic steps, we're going to want to do some more powerful things like removing or replacing text based on particular character patterns. It is time to enter the mystical world of [regular expressions](https://stat.ethz.ch/R-manual/R-devel/library/base/html/regex.html).

Regular expressions (used in many programming languages) offer a way to express complex pattern matching. Let's work through some examples to demonstrate the properties.

```{r regex1, eval = FALSE, echo = TRUE}
# 4 - Remove punctuation
bsText <- gsub(pattern = ";|,|!|?|\\.|\\:|<|>|\\]|\\[", replacement = "", bsText)
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(3,5)</script>IV. Working with Strings<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Intro to Regular Expressions</h2>

You can run `sample(bsText, 10)` and see that our data are looking cleaner...but we still have work to do! Next, let's use regular expressions (commonly just called "regex") to handle some other issues.

```{r moreRegex, echo = TRUE, eval = FALSE}
# 5 - split some common contractions into two words
bsText <- gsub("he('s)", "he is", bsText)
bsText <- gsub("'ll", " will", bsText)

# 6 - Change any numbers to __number__
bsText <- gsub("[:digit:]*", "__number__")
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(4,5)</script>IV. Working with Strings<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Tokenization</h2>

The next task we need to accomplish is **tokenizing** our text, i.e. splitting lines and sentences into individual words. These individual words can then be used downstream to get build a language model and identify key terms.

```{r tokenization, eval = FALSE, echo = TRUE}
# 7- Loop over the vector of lines, split on whitespace, create a list of data.frames
library(stringr)
library(data.table)
allWords <- lapply(
    bsText
    , FUN = function(thisLine){
        return(data.frame(words = str_split(thisLine, " ")[[1]]))
    }
)

# 8 - Put into a data.table and print that just to make sure it worked
wordDT <- data.table::rbindlist(allWords)
wordDT
```

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(5,5)</script>IV. Working with Strings<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Counting Words in Text</h2>

Now that our data are a bit cleaner, it's time to try finding key terms! Broadly speaking, "key terms" in a body of text are those that more common in the text than they are in the language as a whole (e.g. "the" will never be a key word). We aren't looking at any actual data on the distribution of words in Shakespeare-era English in this exercise, so we'll just drop the top 20 words and call the next 20 "key".

The `data.table` package makes this operation easy to carry out.

```{r countTheWords, eval = FALSE, echo = TRUE}
# 9 - Get Word counts and sort by those counts
wordCountDT <- wordDT[, .N, by = words]
data.table::setnames(wordCountDT, old = "N", new = "word_count")
data.table::setorder(wordCountDT, -word_count)
wordCountDT

key_words <- wordCountDT[21:40]
```

--- .section_slide

<h2>Section V.</h2>
<hr></hr>
</br></br></br>
<h2>Final Project Discussion</h2>

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(1,3)</script>V. Final Project Discussion<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Code Review Tips</h2>

For your final project, you'll be presenting your code to your classmates in a "code review" style presentation. This should be an informal conversation, not a formal presentation with slides.

Try to hit these main points:

- Introduce the problem you investigated
- Explain the data set
- Show your code and explain the choices you made:
    - Why did you choose the packages you chose?
    - What data structures (data frames, lists, vectors) did you use? Why?
- Give us your general thoughts on how well it went, what you would do if you had more time

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(2,3)</script>V. Final Project Discussion<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Scripting: Style Notes</h2>

Use this slide as a general reference of coding best practices.

- Declare all the dependencies you need in a bunch of `library()` calls at the top of your script(s)
- Set global variables (like file paths) in all-caps near the top of your script(s)
- Use comments like `#===== Section 1 - Do Stuff =====#` to separate major sections of the code
- Namespace any calls to external functions with `::` (e.g. `lubridate::ymd_hms()`)

A sample script following these prescriptions is provided in the [Week 4 Programming Supplement](https://jameslamb.github.io/teaching/mu_rprog/code/Week4_Supplement.html).

--- .content_slide

<footer>
  <hr>
    <script>FooterBubbles(3,3)</script>V. Final Project Discussion<span style="float:right">ECON 6114 - R Programming</span>
</footer>

<h2>Project Q&A</h2>

<br>

<center><img src="assets/img/dwight.jpg" height=700px width=400px></center>
